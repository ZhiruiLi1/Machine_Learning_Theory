{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Homework 10**\n",
    "\n",
    "Due:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Coding Assignment**\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this assignment, you will implement an iterative method for\n",
    "clustering: k-means. Your implementation will be used for a k-means\n",
    "classifier, which will be trained and tested on handwritten digits\n",
    "dataset to classify an exact digit (0 to 9).\n",
    "\n",
    "### Stencil Code & Data\n",
    "\n",
    "You have been provided with the following stencil files:\n",
    "\n",
    "-   `Models`: contains the K-means classifier class that you will\n",
    "    need to fill in.\n",
    "\n",
    "-   `Check Model`: contains a series of tests to ensure you are coding your \n",
    "    model properly.\n",
    "\n",
    "-   `Main`: contains a main function to read data, run classifier and\n",
    "    print/visualize results.\n",
    "\n",
    "-   `kmeans`: contains helper functions for K-means clustering via\n",
    "    iterative improvement that you will need to fill in.\n",
    "\n",
    "### 8x8 Hand-written digits\n",
    "\n",
    "In the `digits.csv` file, each row is an observation of a 8 x 8\n",
    "hand-written digit (0 - 9), containing a label in the first column and 8\n",
    "x 8 = 64 features (pixel values) in the rest of columns.\n",
    "\n",
    "### Data Format\n",
    "\n",
    "We have written all the preprocessing code for you. The dataset is\n",
    "represented by a `namedtuple` with two fields:\n",
    "\n",
    "-   `data.inputs` is a $m \\times p$ NumPy array that contains the binary\n",
    "    features of the $m$ examples, where $p$ is the number of pixels in\n",
    "    each example (64).\n",
    "\n",
    "-   `data.labels` is a $m$-dimensional NumPy array that contains the\n",
    "    labels of the $m$ examples.\n",
    "\n",
    "You can find more infomation on `namedtuple`\n",
    "[**here**](https://docs.python.org/3/library/collections.html#collections.namedtuple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Assignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **K-means Clustering**\n",
    "\n",
    "K-means is a clustering algorithm most often used for unsupervised\n",
    "machine learning. In unsupervised learning, the learner is given a\n",
    "dataset with no labels and attempts to learn some useful representation\n",
    "of the dataset. You may be wondering how K-means can used for\n",
    "classification in this assignment, as the training data is unlabeled. To\n",
    "address this, given a dataset $S = \\{{\\bf x}_{1}, \\dots, {\\bf x}_{m} \\}$\n",
    "\n",
    "-   You will run K-means clustering on the unlabeled training data and\n",
    "    plot the pixel representations of different cluster centers\n",
    "    (centroids): $M = \\{\\mu_1 \\dots \\mu_{10}\\}$, for clusters\n",
    "    $C=\\{C_{1} \\dots C_{10}\\}$. With K = 10, these cluster centers\n",
    "    should vaguely resemble the 10 digits (0-9).\n",
    "\n",
    "-   Using the pixel plots of the centroids, you will manually assign\n",
    "    which digit each centroid represents.: $A = {a_1 \\dots a_{10}}$.\n",
    "\n",
    "-   To predict the label, $y_{m+1}$ of a new datapoint ${\\bf x}_{m+1}$,\n",
    "    find the cluster center nearest to ${\\bf x}_{m+1}$, $\\mu_i$, and\n",
    "    predict using your assignment, $a_i$.\n",
    "\n",
    "*Note:* You don't need to worry about changing your centroid assignments\n",
    "in between runs, as we've set the random seed in the stencil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "1.  `Models`\\\n",
    "    In this file, you will implement two functions. They are:\n",
    "\n",
    "    -   `KmeansClassifier`\n",
    "\n",
    "        -   **train()**: Learn K=10 cluster centroids (representatives)\n",
    "            from the data that are robust (because they are estimated\n",
    "            using a lot of data). Store cluster centroids as a Numpy\n",
    "            array in *model attribute*\n",
    "\n",
    "        -   **predict()**: predict label of inputs using the label of\n",
    "            closest centroid's assignment\n",
    "\n",
    "2.  `kmeans`:\\\n",
    "    In this file, you will implement four functions:\n",
    "\n",
    "    -   **init_centroids()**: pick **K** random data points as cluster\n",
    "        centers called centroids.\n",
    "\n",
    "    -   **assign_step()**: assign each data instance to its nearest\n",
    "        cluster centroid using Euclidean distance measure.\n",
    "\n",
    "    -   **update_step()**: find the new cluster centroids by taking the\n",
    "        average of its assigned data points.\n",
    "\n",
    "    -   **kmeans()**: run the $K$-means algorithm: initialize centroids,\n",
    "        then repeat the assignment step and update step until the\n",
    "        proportion the centroids \\[defined below\\] change between two\n",
    "        iterations is below a tolerance threshold or the maximum\n",
    "        iteration time is met. The tolerance threshold is passed into\n",
    "        `kmeans()` as `tol` and tolerance is compared against the ratio\n",
    "        of the norm of the difference between centroids and the norm of\n",
    "        the original centroids.\n",
    "\n",
    "    *Note:* You might also want to create a separate function that\n",
    "    calculates the Euclidean distance between two data points in the\n",
    "    `kmeans` file. Please feel free to do so.\n",
    "\n",
    "3.  `main`:\\\n",
    "    You will not need to implement any functions in this file. However,\n",
    "    you will need to do two things:\n",
    "\n",
    "    -   Uncomment the call to `plot_Kmeans` in main. This function will\n",
    "        allow you to see the centroids that your k-means model learns.\n",
    "\n",
    "        **Please note:** to complete the report you will need access to\n",
    "        graphics on the machine you are working on. If you are running\n",
    "        locally or through FastX/XQuartz, you do not have to worry about\n",
    "        this. If you have been working exclusively through ssh, please\n",
    "        read about how to set up remote work that is compatible with\n",
    "        this assignment\n",
    "        **[here](https://cs.brown.edu/about/system/connecting/fastx/)**.\n",
    "        If there are any limitations to you doing this (e.g. not having\n",
    "        access to a personal computer), please email.\n",
    "\n",
    "    -   Fill in the `centroid_assignments` array using the results of\n",
    "        `plot_Kmeans` in your call to `test_Kmeans`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Kmeans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def init_centroids(k, inputs):\n",
    "    \"\"\"\n",
    "    Selects k random rows from inputs and returns them as the chosen centroids\n",
    "    Hint: use random.sample (it is already imported for you!)\n",
    "    :param k: number of cluster centroids\n",
    "    :param inputs: a 2D Numpy array, each row of which is one input\n",
    "    :rand: random seed to be used when sampling from inputs\n",
    "    :return: a Numpy array of k cluster centroids, one per row\n",
    "    \"\"\"\n",
    "    row_indeices = random.sample(range(inputs.shape[0]), k)\n",
    "    return inputs[row_indeices]\n",
    "\n",
    "\n",
    "def assign_step(inputs, centroids):\n",
    "    \"\"\"\n",
    "    Determines a centroid index for every row of the inputs using Euclidean Distance\n",
    "    :param inputs: inputs of data, a 2D Numpy array\n",
    "    :param centroids: a Numpy array of k current centroids\n",
    "    :return: a Numpy array of centroid indices, one for each row of the inputs\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    distances = np.zeros([len(inputs),len(centroids)])\n",
    "    for i in range(len(inputs)):\n",
    "        for j in range(len(centroids)):\n",
    "            distances[i,j] = np.linalg.norm(inputs[i] - centroids[j])\n",
    "    return np.argmin(distances, axis=1)\n",
    "\n",
    "\n",
    "def update_step(inputs, indices, k):\n",
    "    \"\"\"\n",
    "    Computes the centroid for each cluster\n",
    "    :param inputs: inputs of data, a 2D Numpy array\n",
    "    :param indices: a Numpy array of centroid indices, one for each row of the inputs\n",
    "    :param k: number of cluster centroids, an int\n",
    "    :return: a Numpy array of k cluster centroids, one per row\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    centroids = np.zeros([k, inputs.shape[1]])\n",
    "    for i in range(k):\n",
    "        centroids[i] = np.sum(inputs[indices==i],axis=0) / sum(indices==i)\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def kmeans(inputs, k, max_iter, tol):\n",
    "    \"\"\"\n",
    "    Runs the K-means algorithm on n rows of inputs using k clusters via iterative improvement\n",
    "    :param inputs: inputs of data, a 2D Numpy array\n",
    "    :param k: number of cluster centroids, an int\n",
    "    :param max_iter: the maximum number of times the algorithm can iterate trying to optimize the centroid values, an int\n",
    "    :param tol: the tolerance we determine convergence with when compared to the ratio as stated on handout\n",
    "    :param rand: a given random seed to be used within init_centroids\n",
    "    :return: a Numpy array of k cluster centroids, one per row\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    old_centroids = init_centroids(k, inputs)\n",
    "    converge = False\n",
    "    iter = 0\n",
    "    while converge == False:\n",
    "        indices = assign_step(inputs, old_centroids)\n",
    "        new_centroids = update_step(inputs, indices, k)\n",
    "        iter += 1\n",
    "        ratio = np.linalg.norm(new_centroids - old_centroids) / np.linalg.norm(old_centroids)\n",
    "        \n",
    "        if iter > max_iter or ratio < tol:\n",
    "            converge = True\n",
    "\n",
    "        old_centroids = new_centroids\n",
    "    return new_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KmeansClassifier(object):\n",
    "    \"\"\"\n",
    "    K-Means Classifier via Iterative Improvement\n",
    "    @attrs:\n",
    "        k: The number of clusters to form as well as the number of centroids to\n",
    "           generate (default = 10), an int\n",
    "        tol: Value specifying our convergence criterion. If the ratio of the\n",
    "             distance each centroid moves to the previous position of the centroid\n",
    "             is less than this value, then we declare convergence.\n",
    "        max_iter: the maximum number of times the algorithm can iterate trying\n",
    "                  to optimize the centroid values, an int,\n",
    "                  the default value is set to 500 iterations\n",
    "        cluster_centers_: a Numpy array where each element is one of the k cluster centers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters = 10, max_iter = 500, threshold = 1e-6):\n",
    "        \"\"\"\n",
    "        Initiate K-Means with some parameters\n",
    "        \"\"\"\n",
    "        self.k = n_clusters\n",
    "        self.tol = threshold\n",
    "        self.max_iter = max_iter\n",
    "        self.cluster_centers_ = np.array([])\n",
    "\n",
    "    def train(self, X):\n",
    "        \"\"\"\n",
    "        Compute K-Means clustering on each class label and store your result in self.cluster_centers_\n",
    "        :param X: inputs of training data, a 2D Numpy array\n",
    "        :param rand: random seed to be used during training\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        # TODO (hint: use kmeans())\n",
    "        self.cluster_centers_ = kmeans(X, self.k, self.max_iter, self.tol)\n",
    "\n",
    "    def predict(self, X, centroid_assignments):\n",
    "        \"\"\"\n",
    "        Predicts the label of each sample in X based on the assigned centroid_assignments.\n",
    "        :param X: A dataset as a 2D Numpy array\n",
    "        :param centroid_assignments: a Numpy array of 10 digits (0-9) representing the interpretations of the digits of the plotted centroids\n",
    "        :return: A Numpy array of predicted labels\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: complete this step only after having plotted the centroids!\n",
    "        predictions = np.zeros(len(X))\n",
    "        for i in range(len(X)):\n",
    "            distances = np.zeros(self.k)\n",
    "            for j in range(self.k):\n",
    "                distances[j] = np.linalg.norm(X[i] - self.cluster_centers_[j])\n",
    "            centroids = np.argmin(distances)\n",
    "            predictions[i] = centroid_assignments[centroids]\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def accuracy(self, data, centroid_assignments):\n",
    "        \"\"\"\n",
    "        Compute accuracy of the model when applied to data\n",
    "        :param data: a namedtuple including inputs and labels\n",
    "        :return: a float number indicating accuracy\n",
    "        \"\"\"\n",
    "        pred = self.predict(data.inputs, centroid_assignments)\n",
    "        return np.mean(pred == data.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Check Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "from collections import namedtuple\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# Creates Test Model with 3 clusters\n",
    "test_model1 = KmeansClassifier(3)\n",
    "# Creates Test Model with 3 clusters\n",
    "test_model2 = KmeansClassifier(2)\n",
    "\n",
    "# Creates Test Data\n",
    "x = np.array([[0,1,7], [1,1,9], [5,0,1], [4,1,1], [0,5,0], [1,9,0]])\n",
    "y = np.array([2,2,0,0,1,1])\n",
    "x2 = np.array([[3,1,7], [5,1,9], [2,8,1], [0,1,1], [0,5,0], [2,0,8]])\n",
    "y2 = np.array([1,1,0,0,0,1])\n",
    "data = namedtuple('Dataset', ['inputs', 'labels'])\n",
    "test_data1 = data(x, y)\n",
    "test_data2 = data(x2, y2)\n",
    "\n",
    "# Test Train Model and Checks Cluster Centers\n",
    "test_model1.train(x)\n",
    "test_model2.train(x2)\n",
    "test_model1_sorted_clusters = test_model1.cluster_centers_[test_model1.cluster_centers_[:, 0].argsort()]\n",
    "test_model2_sorted_clusters = test_model2.cluster_centers_[test_model2.cluster_centers_[:, 0].argsort()]\n",
    "assert (test_model1_sorted_clusters == np.array([[.5, 7, 0], [.5, 1, 8], [4.5, .5, 1]])).all()\n",
    "assert (test_model2_sorted_clusters == np.array([[1.25, 1.75, 4], [3.5, 4.5, 5]])).all()\n",
    "\n",
    "# Tests Model Predict\n",
    "assert (np.sort(test_model1.predict(x, [0,1,2])) == [0, 0, 1, 1, 2, 2]).all()\n",
    "assert (np.sort(test_model2.predict(x2, [0,1])) == [0, 0, 1, 1, 1, 1]).all()\n",
    "\n",
    "# Tests Model Accuracy\n",
    "assert test_model1.accuracy(test_data1, [0,1,2]) == 1.0\n",
    "assert test_model2.accuracy(test_data2, [0,1]) == .5\n",
    "\n",
    "# TODO: student should print their names and date\n",
    "print('student name and date ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## KMEANS HELPERS ##\n",
    "def plot_Kmeans(model):\n",
    "    \"\"\"\n",
    "        Takes in a pre-trained K-Means classifier model and plots the 10 centroids.\n",
    "        Note: this function is designed only for the digits.csv data set.\n",
    "    :param model: pre-trained K-Means classifier model object\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if isinstance(model, KmeansClassifier) == False:\n",
    "        print(\"Invalid input! Model must be a KmeansClassifier object.\")\n",
    "        return\n",
    "\n",
    "    cluster_centers = model.cluster_centers_\n",
    "    fig, ax = plt.subplots(1, len(cluster_centers), figsize=(3, 1))\n",
    "\n",
    "    for i in range(len(cluster_centers)):\n",
    "        axi = ax[i]\n",
    "        center = cluster_centers[i]\n",
    "        center = np.array(center).reshape(8,8)\n",
    "        axi.set(xticks=[], yticks=[])\n",
    "        axi.imshow(center, interpolation='nearest', cmap=plt.cm.binary)\n",
    "    plt.show()\n",
    "\n",
    "def test_Kmeans(model, test_data, centroid_assignments):\n",
    "    \"\"\"\n",
    "        Prints the accuracy of model on test_data, based on the centroid ordering provided by the student.\n",
    "    :param model: pre-trained K-Means classifier model object\n",
    "    :param test_data: a namedtuple including test inputs and test train_labels\n",
    "    :param centroid_assignments: a python list of 10 digits (0-9) representing your interpretations of the digits of the plotted centroids from plot_Kmeans (in order from left ot right).\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    if isinstance(centroid_assignments, list) == False:\n",
    "        print(\"Invalid input! Centroid assignments must be a python list!\")\n",
    "        return\n",
    "    elif not np.array_equal(np.array(list(range(10))), np.sort(np.array(centroid_assignments))):\n",
    "        print(\"Invalid Input! Centroid assignments must contain all numbers in the range 0-9 (in the order displayed in your plot).\")\n",
    "        return \n",
    "    elif isinstance(model, KmeansClassifier) == False:\n",
    "        print(\"Invalid input! Model must be a KmeansClassifier object.\")\n",
    "        return\n",
    "   \n",
    "    accuracy = model.accuracy(test_data, centroid_assignments)\n",
    "    print(\"Testing on K-Means Classifier (K = \" + str(model.k) + \"), the accuracy is {:.2f}%\".format(accuracy * 100))\n",
    "    return accuracy\n",
    "\n",
    "def runKMeans():\n",
    "    '''\n",
    "        Trains, plots, and tests K-Means classifier on digits.csv dataset.\n",
    "    '''\n",
    "    NUM_CLUSTERS = 10 # Change only for Question 3 of the Project Report\n",
    "    random.seed(1) # DO NOT CHANGE\n",
    "    np.random.seed(1) # DO NOT CHANGE\n",
    "\n",
    "    Dataset = namedtuple('Dataset', ['inputs', 'labels'])\n",
    "\n",
    "    # Read data\n",
    "    data = pd.read_csv(\"digits.csv\", header = 0)\n",
    "\n",
    "    # We assume labels are in the first column of the dataset\n",
    "    labels = data.values[:, 0]\n",
    "\n",
    "    # If labels are of type string, convert class names to numeric values\n",
    "    if isinstance(labels[0], str):\n",
    "        classes = np.unique(labels)\n",
    "        class_mapping = dict(zip(classes, range(0, len(classes))))\n",
    "        labels = np.vectorize(class_mapping.get)(labels)\n",
    "\n",
    "    # Features columns are indexed from 1 to the end, make sure that dtype = float32\n",
    "    inputs = data.values[:, 1:].astype(\"float32\")\n",
    "\n",
    "    # Split data into training set and test set with a ratio of 2:1\n",
    "    train_inputs, test_inputs, train_labels, test_labels = train_test_split(inputs, labels, test_size = 0.33)\n",
    "\n",
    "    all_data = Dataset(inputs, labels)\n",
    "    train_data = Dataset(train_inputs, train_labels)\n",
    "    test_data = Dataset(test_inputs, test_labels)\n",
    "    print(\"Shape of training data inputs: \", train_data.inputs.shape)\n",
    "    print(\"Shape of test data inputs:\", test_data.inputs.shape)\n",
    "\n",
    "    # Train K-Means Classifier\n",
    "    kmeans_model = KmeansClassifier(NUM_CLUSTERS)\n",
    "    kmeans_model.train(train_data.inputs)\n",
    "\n",
    "    # DO NOT MODIFY ABOVE THIS LINE!\n",
    "\n",
    "    # TODO: uncomment below to plot the centroids for the 10 digits (0-9).\n",
    "    plot_Kmeans(kmeans_model)\n",
    "\n",
    "    # TODO: fill out centroid_assignments below based on the visualization of plot_Kmeans (in order from left to right).\n",
    "    #   In this step, you are assigning each centroid to its most resembling digit (0-9).\n",
    "    #   DO NOT add print lines below test_Kmeans on final handin\n",
    "    #   (Comment out this line when running Question 3 of the Project Report)\n",
    "    test_Kmeans(kmeans_model, test_data, centroid_assignments=[9,2,1,4,3,0,8,6,5,7])\n",
    "\n",
    "# DO NOT MODIFY BELOW\n",
    "runKMeans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project Report**\n",
    "\n",
    "### **Question 1**\n",
    "Display your output of `plot_Kmeans()`. Does your plot match your expectations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "Plot should look like the image below. Some possible\n",
    "answers could include: all numbers 0-9 are present, numbers in\n",
    "general are fuzzier or less fuzzy than expected, certain numbers\n",
    "like 7 are fuzzier due to variation in how people write it, etc.\n",
    "\n",
    "![image](kmeans_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 2**\n",
    "In this assignment, you implemented k-means through a Euclidean\n",
    "distance metric. Describe other distance metrics that can be used\n",
    "and how they cluster inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "Many possible answers. Ex) Manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 3**\n",
    "In `runKMeans()` in the Main section, change the number of clusters (`NUM_CLUSTERS`) to 6, and display the digits with `plot_Kmeans(kmeans_model)`. Do this as well for 15 clusters. Describe what the clutsers' centers (centroids) look like and why this is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "If $K<10$, clusters would be more difficult to\n",
    "read/interpret since some would be a blend of two or more\n",
    "\\\"similar\\\" digits. (Ex: 1 and 7 might be the same cluster).\n",
    "\n",
    "If $K>10$, our clusters will begin distinguishing between different\n",
    "ways of writing the same digit. (Ex: 4 with the leftmost edge\n",
    "slanted vs vertical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "bcd9bc17ffadb8b3c09124f861805f4f094648af93180b87f0218364b7d0c0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
